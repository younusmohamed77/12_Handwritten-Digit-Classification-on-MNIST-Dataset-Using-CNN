{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd08191-b998-4bc4-953a-baf4379ad4cc",
   "metadata": {},
   "source": [
    "### Exercise 1: Basic custom training loop: \n",
    "\n",
    "#### 1. Set Up the Environment:\n",
    "\n",
    "- Import necessary libraries. \n",
    "\n",
    "- Load and preprocess the MNIST dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab175dce-64b7-48f5-814a-34d5d7f7fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf \n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "# Suppress all Python warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56b456b-7ac3-43a0-8fac-c8e3159fa32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6584d-ab1c-47c8-bce8-736cca05c9d4",
   "metadata": {},
   "source": [
    "#### 2. Define the model: \n",
    "\n",
    "Create a simple neural network model with a Flatten layer followed by two Dense layers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36e5194-f5aa-4bb9-b531-cef36f66215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the Model\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421d326-f84b-4d80-8a38-ec94c9cbeac7",
   "metadata": {},
   "source": [
    "#### 3. Define Loss Function and Optimizer: \n",
    "\n",
    "- Use Sparse Categorical Crossentropy for the loss function. \n",
    "- Use the Adam optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167de5f3-2e75-4dd9-a2a6-54fb4a7cc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Loss Function and Optimizer\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f88ed5-26ca-43d3-ae0c-e8dc9aeb4296",
   "metadata": {},
   "source": [
    "#### 4. Implement the Custom Training Loop: \n",
    "\n",
    "- Iterate over the dataset for a specified number of epochs. \n",
    "- Compute the loss and apply gradients to update the model's weights. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6541f938-6c23-4cb1-94a1-cf78da0a6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 2.3405046463012695\n",
      "Epoch 1 Step 200: Loss = 0.36829257011413574\n",
      "Epoch 1 Step 400: Loss = 0.17630800604820251\n",
      "Epoch 1 Step 600: Loss = 0.18394115567207336\n",
      "Epoch 1 Step 800: Loss = 0.15692219138145447\n",
      "Epoch 1 Step 1000: Loss = 0.49224311113357544\n",
      "Epoch 1 Step 1200: Loss = 0.19099357724189758\n",
      "Epoch 1 Step 1400: Loss = 0.2312314510345459\n",
      "Epoch 1 Step 1600: Loss = 0.18971657752990723\n",
      "Epoch 1 Step 1800: Loss = 0.15039554238319397\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.09234731644392014\n",
      "Epoch 2 Step 200: Loss = 0.11811450123786926\n",
      "Epoch 2 Step 400: Loss = 0.12463423609733582\n",
      "Epoch 2 Step 600: Loss = 0.06313656270503998\n",
      "Epoch 2 Step 800: Loss = 0.07661774754524231\n",
      "Epoch 2 Step 1000: Loss = 0.28841260075569153\n",
      "Epoch 2 Step 1200: Loss = 0.12323574721813202\n",
      "Epoch 2 Step 1400: Loss = 0.11338256299495697\n",
      "Epoch 2 Step 1600: Loss = 0.13902071118354797\n",
      "Epoch 2 Step 1800: Loss = 0.08673415333032608\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Implement the Custom Training Loop\n",
    "\n",
    "epochs = 2\n",
    "# train_dataset = train_dataset.repeat(epochs)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)  # Forward pass\n",
    "            loss_value = loss_fn(y_batch_train, logits)  # Compute loss\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Logging the loss every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9da508-6263-4add-b915-2e651ae2cd04",
   "metadata": {},
   "source": [
    "### Exercise 2: Adding Accuracy Metric:\n",
    "\n",
    "Enhance the custom training loop by adding an accuracy metric to monitor model performance. \n",
    "\n",
    "#### 1. Set Up the Environment: \n",
    "\n",
    "Follow the setup from Exercise 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84862b-dfba-4f98-a2ae-85956c3dde88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
